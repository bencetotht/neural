{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting important features using SelectFromModel\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the random forest model and fit to the training data\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Define the feature selection object\n",
    "model = SelectFromModel(rf, prefit=True)\n",
    "\n",
    "# Transform the training features\n",
    "X_train_transformed = model.transform(X_train)\n",
    "\n",
    "original_features = df.columns[:-1]\n",
    "print(f\"Original features: {original_features}\")\n",
    "\n",
    "# Select the features deemed important by the SelectFromModel\n",
    "features_bool = model.get_support()\n",
    "\n",
    "selected_features = X_train.columns[features_bool]\n",
    "print(f\"\\nSelected features: {selected_features}\")\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": selected_features,\n",
    "    \"importance\": rf.feature_importances_[features_bool]\n",
    "})\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance[\"feature\"], feature_importance[\"importance\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC model in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC model\n",
    "# Import required modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Split the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the SVM / SVC model\n",
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions from the model\n",
    "y_pred = svc_model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kfold cross-validation with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold cross-validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create a KFold object\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Get the train and test data from the first split from the shuffled KFold\n",
    "train_data_split, test_data_split = next(kfold.split(df_X))\n",
    "\n",
    "# Compute the cross-validation score\n",
    "score = cross_val_score(model, df_X, df_y, scoring='balanced_accuracy', cv=kfold)\n",
    "print(score)\n",
    "\n",
    "# Get model predictions\n",
    "y_pred = model.predict(df_X)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = confusion_matrix(df_y, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# Initialize the MLflow experiment\n",
    "mlflow.set_experiment(\"Logistic Regression Prediction\")\n",
    "\n",
    "# Start a run, log model coefficients and intercept\n",
    "with mlflow.start_run():\n",
    "    for idx, coef in enumerate(model.coef_[0]):\n",
    "        mlflow.log_param(f\"coef_{idx}\", coef)\n",
    "    mlflow.log_param(\"intercept\", model.intercept_[0])\n",
    "\t\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    print(run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kolmogorov-smirnov test with scipy and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datadrift detection using kolmogorov-smirnov test\n",
    "# Import the ks_2samp function\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Calculate and print the balanced accuracy of the model\n",
    "balanced_accuracy_jan = 60.0\n",
    "balanced_accuracy_feb = balanced_accuracy_score(true_labels, predicted_labels) * 100\n",
    "print(f\"Model Balanced Accuracy In February: {balanced_accuracy_feb:.2f}%\")\n",
    "print(f\"Is there a decline in accuracy? {'Yes' if balanced_accuracy_feb < balanced_accuracy_jan else 'No'}\")\n",
    "\n",
    "# Use the Kolmogorov-Smirnov test to check for data drift\n",
    "ks_statistic, p_value = ks_2samp(jan_data_samples, feb_data_samples)\n",
    "\n",
    "significant_drift = p_value < 0.05\n",
    "\n",
    "print(f\"Kolmogorov-Smirnov Statistic: {ks_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Is there significant data drift? {'Yes' if significant_drift else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
